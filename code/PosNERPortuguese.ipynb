{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento das Entidades \n",
    "\n",
    "Nesse notebook, os arquivos gerados pelo BERT são processados para a geração dos arquivos finais com as entidades. O processamento consiste em eliminar algumas entidades que não ajudam muito no entendimento do texto, como: 'Presidente', 'Ministro', 'Sr', 'Sra'. O objetivo é deixar em evidência entidades que tragam mais informação para a análise dos textos processados, como por exemplo: Presidente da República, Senador Randolfe e assim por diante. \n",
    "\n",
    "Essa eliminação foi feita de forma manual, selecionando algumas entidades para cada uma das classes extraídas. \n",
    "\n",
    "Outro processamento realizado foi a unificação de termos como COVID e COVID-19. \n",
    "\n",
    "Por fim, as entidades das classes `COISA`, `ABSTRACCAO`, `OUTRO`, `OBRA` e `ACONTECIMENTO` foram agrupadas em uma única entidade: `OUTROS`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras removidas por entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = {'PESSOA': [\n",
    "    'Sr. Presidente',\n",
    "    'Sr. Relator',\n",
    "    'Prefeitos',\n",
    "    'Presidente',\n",
    "    'Senador',\n",
    "    'Senadora',\n",
    "    'Ministro',\n",
    "    'Governador',\n",
    "    'Senhor',\n",
    "    'Excelência',\n",
    "    'Relator',\n",
    "    'V. Exa.',\n",
    "    'V. Exa',\n",
    "    'V. Exas',\n",
    "    'Governador do',\n",
    "    'Srs.',\n",
    "    'Sr.',\n",
    "    'Sra',\n",
    "    'Sras',\n",
    "    'Sra.',\n",
    "    'Sras.',\n",
    "    'Sr',\n",
    "    'Srs',\n",
    "    'Secretário de',\n",
    "    'Covid-19',\n",
    "    'Governador',\n",
    "    'Governadores',\n",
    "    'Prefeitos',\n",
    "    'Sras. Senadoras',\n",
    "    'Senadores', 'Senadoras', 'Sr. Senador', 'Srs. Senadores', 'Deputado', 'Secretário', 'Secretários',\n",
    "    'Parlamentar', 'Parlamentares', 'Deputados', ],\n",
    "    'LOCAL': ['Território', 'Brasil', 'País', 'Município', 'Municípios', 'Estado', 'Estados', 'Países', 'Covid-19'],\n",
    "    \"ORGANIZACAO\": ['Município', 'Governo', 'Municípios', 'Estado', 'Estados', 'Países', 'País', 'Brasil', 'Covid-19', 'China'],\n",
    "    \"OUTROS\": ['Covid-19', 'País', 'Programa', 'Medicina']\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapeamento para unificar algunas alguns termos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_words = {\n",
    "    'Covid': 'Covid-19',\n",
    "    'Programa Nacional de Imunizações': 'PNI'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes que foram agrupadas em Outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_outros = ['COISA','ABSTRACCAO','OUTRO','OBRA','ACONTECIMENTO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir acessa cada arquivo gerado pelo modelo de Reconhecimento de Entidades nomeadas e agrupa em duas variáveis: `all_entites` que tem todas as entidades independente do dia e `all_entities_date` que agrupa por data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path_ = \"../output/ner_depoentes_convidados/ner_files/\"\n",
    "\n",
    "all_files = os.listdir(path_)\n",
    "\n",
    "all_entites_by_date = {}\n",
    "all_entites = {}\n",
    "all_entities_by_date_name = {}\n",
    "\n",
    "\n",
    "for file_ in all_files:\n",
    "    file_split = file_.split(\"_\")\n",
    "    date_ = file_split[1]\n",
    "    name_ = ' '.join(file_split[2:]).split(\".\")[0]\n",
    "    \n",
    "    with open(path_ + file_) as datafile:\n",
    "        data_ = json.load(datafile)\n",
    "\n",
    "    final_dict = {}\n",
    "    for data in data_[0]['entities']:\n",
    "        text_ = data['text']\n",
    "        text_ = text_.strip()\n",
    "\n",
    "        if text_ in map_words.keys():\n",
    "            text_ = map_words[text_]\n",
    "\n",
    "        class_ = data['class']\n",
    "\n",
    "        if class_ in class_to_outros:\n",
    "            class_ = 'OUTROS'\n",
    "        \n",
    "        if class_ in remove_words.keys():\n",
    "            words_to_remove = remove_words[class_]\n",
    "        else:\n",
    "            words_to_remove = []\n",
    "\n",
    "        if text_ not in words_to_remove:\n",
    "\n",
    "\n",
    "\n",
    "            if class_ not in final_dict.keys():\n",
    "                final_dict[class_] = {text_: 1}\n",
    "            else: \n",
    "                if text_ not in final_dict[class_].keys():\n",
    "                    final_dict[class_][text_] = 1\n",
    "                else:\n",
    "                    final_dict[class_][text_] += 1\n",
    "\n",
    "            if class_ not in all_entites.keys():\n",
    "                all_entites[class_] = {text_: 1}\n",
    "            else:\n",
    "                if text_ not in all_entites[class_].keys():\n",
    "                    all_entites[class_][text_] = 1\n",
    "                else:\n",
    "                    all_entites[class_][text_] += 1\n",
    "\n",
    "            if date_ not in all_entites_by_date.keys():\n",
    "                all_entites_by_date[date_] = {}\n",
    "\n",
    "            if class_ not in all_entites_by_date[date_].keys():\n",
    "                all_entites_by_date[date_][class_] = {text_: 1}\n",
    "            else: \n",
    "                if text_ not in all_entites_by_date[date_][class_].keys():\n",
    "                    all_entites_by_date[date_][class_][text_] = 1\n",
    "                else:\n",
    "                    all_entites_by_date[date_][class_][text_] += 1\n",
    "\n",
    "\n",
    "    for class_ in final_dict.keys():\n",
    "        final_dict[class_] = dict(sorted(final_dict[class_].items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    if date_ not in all_entities_by_date_name.keys():\n",
    "        all_entities_by_date_name[date_] = [{name_: final_dict}]\n",
    "    else:\n",
    "        all_entities_by_date_name[date_].append({name_: final_dict})\n",
    "\n",
    "    for class_ in all_entites.keys():\n",
    "        all_entites[class_] = dict(sorted(all_entites[class_].items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    for date_ in all_entites_by_date.keys():\n",
    "        for class_ in all_entites_by_date[date_].keys():\n",
    "            all_entites_by_date[date_][class_] = dict(sorted(all_entites_by_date[date_][class_].items(), key=lambda item: item[1], reverse=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>depoente_convidado</th>\n",
       "      <th>tipo_entidade</th>\n",
       "      <th>entidade</th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210504</td>\n",
       "      <td>LUIZ HENRIQUE MANDETTA</td>\n",
       "      <td>ORGANIZACAO</td>\n",
       "      <td>Ministério da Saúde</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210504</td>\n",
       "      <td>LUIZ HENRIQUE MANDETTA</td>\n",
       "      <td>ORGANIZACAO</td>\n",
       "      <td>SUS</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210504</td>\n",
       "      <td>LUIZ HENRIQUE MANDETTA</td>\n",
       "      <td>ORGANIZACAO</td>\n",
       "      <td>Organização Mundial da Saúde</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210504</td>\n",
       "      <td>LUIZ HENRIQUE MANDETTA</td>\n",
       "      <td>ORGANIZACAO</td>\n",
       "      <td>Câmara</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210504</td>\n",
       "      <td>LUIZ HENRIQUE MANDETTA</td>\n",
       "      <td>ORGANIZACAO</td>\n",
       "      <td>Fiocruz</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9711</th>\n",
       "      <td>20210715</td>\n",
       "      <td>CRISTIANO ALBERTO HOSSRI CARVALHO</td>\n",
       "      <td>VALOR</td>\n",
       "      <td>200 milhões</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9712</th>\n",
       "      <td>20210715</td>\n",
       "      <td>CRISTIANO ALBERTO HOSSRI CARVALHO</td>\n",
       "      <td>VALOR</td>\n",
       "      <td>em torno de 20 anos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9713</th>\n",
       "      <td>20210715</td>\n",
       "      <td>CRISTIANO ALBERTO HOSSRI CARVALHO</td>\n",
       "      <td>VALOR</td>\n",
       "      <td>123 Milhas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9714</th>\n",
       "      <td>20210715</td>\n",
       "      <td>FÁBIO HENRIQUE MING MARTINI</td>\n",
       "      <td>PESSOA</td>\n",
       "      <td>Fábio Ming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>20210715</td>\n",
       "      <td>FÁBIO HENRIQUE MING MARTINI</td>\n",
       "      <td>PESSOA</td>\n",
       "      <td>Ming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9716 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          data                 depoente_convidado tipo_entidade  \\\n",
       "0     20210504             LUIZ HENRIQUE MANDETTA   ORGANIZACAO   \n",
       "1     20210504             LUIZ HENRIQUE MANDETTA   ORGANIZACAO   \n",
       "2     20210504             LUIZ HENRIQUE MANDETTA   ORGANIZACAO   \n",
       "3     20210504             LUIZ HENRIQUE MANDETTA   ORGANIZACAO   \n",
       "4     20210504             LUIZ HENRIQUE MANDETTA   ORGANIZACAO   \n",
       "...        ...                                ...           ...   \n",
       "9711  20210715  CRISTIANO ALBERTO HOSSRI CARVALHO         VALOR   \n",
       "9712  20210715  CRISTIANO ALBERTO HOSSRI CARVALHO         VALOR   \n",
       "9713  20210715  CRISTIANO ALBERTO HOSSRI CARVALHO         VALOR   \n",
       "9714  20210715        FÁBIO HENRIQUE MING MARTINI        PESSOA   \n",
       "9715  20210715        FÁBIO HENRIQUE MING MARTINI        PESSOA   \n",
       "\n",
       "                          entidade  frequencia  \n",
       "0              Ministério da Saúde          74  \n",
       "1                              SUS          21  \n",
       "2     Organização Mundial da Saúde          18  \n",
       "3                           Câmara          12  \n",
       "4                          Fiocruz          10  \n",
       "...                            ...         ...  \n",
       "9711                   200 milhões           1  \n",
       "9712           em torno de 20 anos           1  \n",
       "9713                    123 Milhas           1  \n",
       "9714                    Fábio Ming           1  \n",
       "9715                          Ming           1  \n",
       "\n",
       "[9716 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "for date_ in all_entities_by_date_name.keys():\n",
    "    for entry in all_entities_by_date_name[date_]:\n",
    "        line_ = [(date_, key, entitie_type, word, entry[key][entitie_type][word]) for key in entry.keys() for entitie_type in entry[key].keys() for word in entry[key][entitie_type].keys()]\n",
    "        all_data.extend(line_)\n",
    "\n",
    "df_data = pd.DataFrame(all_data, columns=['data','depoente_convidado','tipo_entidade','entidade','frequencia'])\n",
    "df_data.sort_values(by=['data','depoente_convidado'],inplace=True)\n",
    "df_data.reset_index(drop=True,inplace=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dicionários criados são salvos em três arquivos na pasta `output`: \n",
    "\n",
    "* `all_entities`: foi salvo em `todas_entidades_nomeadas.json`.\n",
    "* `all_entities_by_date`: foi salvo em `todas_entidades_nomeadas_por_data.json`.\n",
    "* `all_entities_by_date_name`: foi salvo em `tordas_entidades_nomeadas_por_data_nome.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/todas_entidades_nomeadas.json\", 'w') as outfile:\n",
    "    json.dump(all_entites, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/todas_entidades_nomeadas_por_data.json\", 'w') as outfile:\n",
    "    json.dump(all_entites_by_date, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv(\"../output/todas_entidades_nomeadas_por_data_nome.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f872a193c411d785a417cb451ad65b981e6d66581d470666f03d0d69e08a512e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
